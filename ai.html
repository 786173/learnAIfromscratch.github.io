<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2020-06-16 Tue 07:23 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>An Artificial Intelligence Curriculum</title>
<meta name="generator" content="Org mode">
<meta name="author" content="jbh">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
   body {
    background-color: #ededed;
    margin: auto;
    padding: 0.5rem;
    max-width: 80ch; 
  }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<header>
<h1 class="title">An Artificial Intelligence Curriculum</h1>
</header><nav id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org9b1192d">Intro</a></li>
<li><a href="#org6e16361">Start here</a>
<ul>
<li><a href="#org5f6a7ef">Material req</a></li>
<li><a href="#org844ead3">Lecture 1 Introduction</a></li>
<li><a href="#orgea458a3">Lecture 2 Data collection and scraping</a>
<ul>
<li><a href="#orgcda6987">Regex practice</a></li>
</ul>
</li>
<li><a href="#org7c34b63">Lecture 3 Jupyter notebooks</a></li>
<li><a href="#org8e407f8">Recitation 1</a></li>
<li><a href="#org64e484b">Finite State Automata</a>
<ul>
<li><a href="#org2e09113">Assignment 1</a></li>
<li><a href="#orgc54d175">Assignment 1 15-688 (Optional)</a></li>
</ul>
</li>
<li><a href="#orgcc1561d">Lecture 4 Relational Data</a></li>
<li><a href="#org847d894">Lecture 5 Visualizations</a></li>
<li><a href="#orgca620c2">Lecture 6 Linear Algebra</a>
<ul>
<li><a href="#org692e721">Vector Boot Camp</a></li>
<li><a href="#org7970826">Linear Algebra Review</a></li>
<li><a href="#org8622db2">Future Linear Algebra</a></li>
<li><a href="#org1ee8c79">Assignment 2</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</nav>

<div id="outline-container-org9b1192d" class="outline-2">
<h2 id="org9b1192d">Intro</h2>
<div class="outline-text-2" id="text-org9b1192d">
<p>
This is an (ongoing) workshop, Part II in the <a href="https://learnaifromscratch.github.io">AI Tripos</a>. 
</p>
</div>
</div>

<div id="outline-container-org6e16361" class="outline-2">
<h2 id="org6e16361">Start here</h2>
<div class="outline-text-2" id="text-org6e16361">
<p>
We start with CMU's 15-388/688 <a href="http://www.datasciencecourse.org/lectures/">Practical Data Science</a> from fall 2019 because it will teach us the 'full stack' so collection, processing, visualizations, building models using machine learning, and how to diagnose problems. When you finish this course you can get paid to do this in industry while we later take more advanced AI courses.
</p>

<p>
This course assumes some <a href="https://learnaifromscratch.github.io/math.html">math</a> and <a href="https://learnaifromscratch.github.io/software.html">programming</a> background, but the math is all applied in a blackbox way you'll be able to figure out, and if you know higher order functions map/filter/fold and lists from the software workshop you should be fine for the 15-388 assignments whereas the 15-688 assignments assume an entire undergrad already. .
</p>
</div>

<div id="outline-container-org5f6a7ef" class="outline-3">
<h3 id="org5f6a7ef">Material req</h3>
<div class="outline-text-3" id="text-org5f6a7ef">
<p>
Like the software workshop if all you have is access to a phone or tablet it's possible to complete this course using Google colab (free) otherwise the course uses Python3 and provides Vagrant files and instructions to set up your own environment. I went with <a href="https://docs.conda.io/en/latest/miniconda.html">miniconda</a>. All the assignments are handed out as jupyter notebooks, you can certainly do them in PyCharm too if you wanted or vim even. The lectures are through <a href="https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22618ea253-ca45-4b14-9f1d-aab501543bd2%22">panopto</a> and open to the public.  
</p>
</div>
</div>

<div id="outline-container-org844ead3" class="outline-3">
<h3 id="org844ead3">Lecture 1 Introduction</h3>
<div class="outline-text-3" id="text-org844ead3">
<p>
We're watching the first <a href="https://scs.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22618ea253-ca45-4b14-9f1d-aab501543bd2%22">lecture</a> named <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=dfa649d2-639b-4684-bf4e-aab50178338f">introduction</a>. If you want to download these lectures, right-click, open inspector, click on &lt;head id="HeadNode"&gt; and expand the tree, scroll down to &lt;meta property="og:video" content =" &#x2026;"&gt; and cut and paste the .mp4 address into another browser tab, you can now save the video the locally. There's also <a href="http://www.datasciencecourse.org/notes/intro/">notes</a> for this lecture. 
</p>

<p>
This is a great description of statistics, from a book we will be able to complete soon:
</p>

<blockquote>
<p>
Statistics is the branch of mathematical engineering which designs and analyses methods for drawing reliable inferences from imperfect data. The subject of most sciences is some aspect of the world around us, or within us. Psychology studies minds; geology studies the Earth’s composition and form; economics studies production, distribution and exchange; mycology studies mushrooms. Statistics does not study the world, but some of the ways we try to understand the world — some of the intellectual tools of the other sciences. Its utility comes indirectly, through helping those other sciences. This utility is very great, because all the sciences have to deal with imperfect data.
</p>

<p>
Data may be imperfect because we can only observe and record a small fraction of what is relevant; or because we can only observe indirect signs of what is truly relevant; or because, no matter  how carefully we try, our data always contain an element of noise. Over the last two centuries, statistics has come to handle all such imperfections by modeling them as random processes, and probability has become so central to statistics that we introduce random events deliberately (as in sample surveys). Statistics, then, uses probability to model inference from data. We try to mathematically understand the properties of different procedures for drawing inferences: Under what conditions are they reliable? What sorts of errors do they make, and how often? What can they tell us when they work? What are signs that something has gone wrong? Like other branches of engineering  statistics aims not just at understanding but also at improvement: we want to analyze data better: more reliably, with fewer and smaller errors, under broader conditions, faster, and with less mental effort.  &#x2013; <i>Advanced Data Analysis From an Elementary Point of View</i> by <a href="http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/">Cosma Shalizi</a>
</p>
</blockquote>

<p>
All the examples he talks about you can see the slides better in the lecture <a href="http://www.datasciencecourse.org/notes/intro/">notes</a>. The one example about thatched roofs turned out to be a bad indicator as one student mentions. Googling this I discover: "There are many structures in Kenya and Uganda that have thatched roofs, but are not households, such as kitchens and sheds. These buildings were artificially inflating the count of households with thatched roofs, making areas look poorer than they were."
</p>

<p>
We don't have the recommended background but you'll see later most of these requirements are given a crash course enough to finish the assignments. The rest of this lecture is just course logistics, the masters version of this course 15-688 has extra homework assignments, which are up to you if you want to try them.  
</p>
</div>
</div>

<div id="outline-container-orgea458a3" class="outline-3">
<h3 id="orgea458a3">Lecture 2 Data collection and scraping</h3>
<div class="outline-text-3" id="text-orgea458a3">
<p>
Next lecture when he introduces Jupyter notebook, you can export the <a href="http://www.datasciencecourse.org/notes/data_collection/">notes</a> for this lecture as a notebook to experiment around with the regex library, they are fully interactive can run them yourself, change anything to see how corner cases are matched, go through the Python <a href="https://docs.python.org/3.8/tutorial/">tutorial</a> looking up anything you don't understand like what range does or list/dict comprehensions.     
</p>

<p>
The regex poll done in class is explained in the notes:
</p>

<pre class="example">
r"\w+\s+science" 
</pre>

<p>
"These rules can of course be combined with the rules to match potentially very complicated expressions. For instance, if we want to match the text “something science” where something is any alphanumeric character, and there can be any number of spaces of any kind between something and the word “science”, we could use the expression r"\w+\s+science".
</p>
</div>

<div id="outline-container-orgcda6987" class="outline-4">
<h4 id="orgcda6987">Regex practice</h4>
<div class="outline-text-4" id="text-orgcda6987">
<p>
If you want some practice, try <a href="https://regexone.com/lesson/introduction_abcs">this</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-org7c34b63" class="outline-3">
<h3 id="org7c34b63">Lecture 3 Jupyter notebooks</h3>
<div class="outline-text-3" id="text-org7c34b63">
<p>
Watching <a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=063d8956-2b99-4b9c-b2f6-aabf01450eb5">lecture 3</a>. 
</p>

<p>
<b>Colab</b>
If you must it's possible to use Google Colab (python v 3.6) online for <a href="https://colab.research.google.com/">free</a> click on File -&gt; New Notebook and enter in a throwaway or regular google account, a new notebook should appear. Free version of Colab, the VM will shut down after some indeterminate amount of time being idle, which you then have to reset with Runtime -&gt; Restart Runtime. You can back up everything to a Google drive account or Github. You can redefine all the heavily used key shortcuts in Colab so if you're stuck with just a tablet, then redefine Shift-Enter (run and move to new cell) and Ctrl-Enter (run cell) to whatever you want. You can enter shell commands with ! so !cd or !ls or !python &#x2013;version to match up to the online python documentation.
</p>

<p>
<b>Local environment</b>
There is a vagrant installation method here (scroll down to <a href="http://www.datasciencecourse.org/assignments/">environment</a>) but it likely won't install anymore and you'll have to manually <a href="https://app.vagrantup.com/ubuntu/boxes/trusty64">change</a> the box in the Vagrantfile to another ubuntu distro. If you're wondering what Vagrant does in this context, it's a pile of scripts to download and configure a virtual environment, starts up virtualbox, you minimize that window and from command line 'vagrant ssh' into the running VM, so you can start jupyter notebook which gives you a localhost IP, and then whatever regular browser you use can go to that address and run the notebook. You can also install all this with your regular OS though a vm is nice to keep environments seperate as we'll installing pip packages for the course. I took his advice in the lecture and installed <a href="https://docs.anaconda.com/anaconda/install/">Anaconda</a>, actually <a href="https://docs.conda.io/en/latest/miniconda.html">Miniconda</a>, which has a <a href="https://conda.io/projects/conda/en/latest/_downloads/843d9e0198f2a193a3484886fa28163c/conda-cheatsheet.pdf">cheat sheet</a> for it's package manager (Python is so complex now that it needs distros). One reason anaconda exists is because there are countless scientific libraries and that all require a specific environment of python to run so anaconda solves this problem, and in many research labs and bigcorps you need written permission to download and install new software from the various layers of corporate security officers so anaconda full install can give you everything up front. Other solutions exist like NixOS or Guix in order to run multiple different versions of the same software.
</p>

<p>
His shill of python growth based on the amount of stackoverflow questions could also mean the documentation is terrible or error messages so cryptic that everybody needs to consult stackoverflow. For our use in this course, which is hacking around with data, scripting it into various datastructures, visualization, and machine learning, Python is the obvious choice because of the libraries available like Facebook's Pytorch. If whatever prototype you come up with needs to be deployed in some other language there is a C++ API for Pytorch.  
</p>


<p>
I assume you have a notebook open while he's going through the lab. Note the syntax of python is nearly identical to what we've been using in the other workshop (pyret, with is python + racket) except each function needs a return statement.     
</p>

<ul class="org-ul">
<li>Efficiency lists:
<ul class="org-ul">
<li>Accessing a list element O(1)</li>
<li>Appending O(1)</li>
<li>Inserting O(n) due to 'lists' being an array</li>
<li>If you forgot efficiency from CS019 see <a href="https://www.cs.cmu.edu/~112/notes/notes-efficiency.html">this</a></li>
<li>There's a somewhat accurate list of python <a href="https://wiki.python.org/moin/TimeComplexity">builtins</a> complexity</li>
</ul></li>
</ul>

<p>
Note he uses a <a href="https://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell%20Magics.ipynb">magic</a> command for %%timeit. 
</p>

<ul class="org-ul">
<li>Efficiency dicts:
<ul class="org-ul">
<li>Value lookup O(1)</li>
<li>Insert O(1)</li>
<li>Delete O(1)
<ul class="org-ul">
<li>Worse time constant than lists</li>
<li>Use for more complex type than integers</li>
</ul></li>
</ul></li>
</ul>

<p>
Classes, methods and OOP in python are explained <a href="https://www.cs.cmu.edu/~112/notes/notes-oop-part1.html">here</a> and <a href="https://www.cs.cmu.edu/~112/notes/notes-oop-part2.html">here</a>, more <a href="https://www.cs.cmu.edu/~112/notes/notes-oop-part3.html">here</a> and finally using sets and dictionaries in <a href="https://www.cs.cmu.edu/~112/notes/notes-oop-part4.html">classes</a> but we won't be using any kind of complex OOP or engineering software in this course just scripting together libraries.    
</p>
</div>
</div>

<div id="outline-container-org8e407f8" class="outline-3">
<h3 id="org8e407f8">Recitation 1</h3>
<div class="outline-text-3" id="text-org8e407f8">
<p>
Let's do the first <a href="http://www.datasciencecourse.org/notes/recitation_1/">recitation</a>. Download the Jupyter <a href="http://www.datasciencecourse.org/notes/recitation_1/recitation_1.tar.gz">notebook</a> for this recitation and <a href="https://explainshell.com/explain?cmd=tar++-xvf+recitation_1.tgz">untar</a> it, open the .ipynb file in jupyter notebook and now you can run all the code. 
</p>

<p>
If you're using Google Colab, look at <a href="https://colab.research.google.com/notebooks/io.ipynb">this</a> otherwise <a href="https://stackoverflow.com/a/52300696">mount</a> a google drive, save the homework .tar.gz file directly to your google drive, and use something like ZIP extractor to open it there. Other method is open a new notebook in colab and type the following, then File -&gt; Open from drive and load the .ipnyb notbook and run all code blocks Runtime -&gt; Run All
</p>

<pre class="example">
!wget http://www.datasciencecourse.org/notes/recitation_1/recitation_1.tar.gz
!tar -xvf recitation_1.tar.gz
!cp recitation_1.ipynb '/content/drive/My Drive' 

# note this can all be automated with python (pydrive) or google colab library
</pre>

<p>
Run all the cells (Cell -&gt; Run All). Recitation begins with notes about testing, in every homework assignment notebook it comes with a large amount of tests already written for us. The 'from' statement is of course importing a <a href="https://www.cs.cmu.edu/~112/notes/notes-variables-and-functions.html#ModuleFunctions">library</a>. This recitation is self explanatory, notice what 'pprint(dict(response.headers))' did, returned the header in a dictionary with keys. Anytime you want try some examples yourself insert a code cell below what you want to manipulate. 
</p>

<p>
They show that Python libraries can create encoding conflicts. Remember code points from cs019, <a href="https://wiki.sei.cmu.edu/confluence/display/c/MSC10-C.+Character+encoding:+UTF8-related+issues">Unicode/UTF-8</a> replaces ASCII, ISO 8859 and other encodings, and supports any written language characters. These encodings are all different ways to interpret raw bytes and represent <a href="https://docs.python.org/3/howto/unicode.html">textual data</a>.
</p>

<p>
Regexp they want us to <a href="https://blog.codinghorror.com/regular-expressions-now-you-have-two-problems/">read</a> a blog, it can be summarized as: break up your regexp into newlines so it's not a massive oneliner, use comments so you don't forget what you wrote, use a regexp tool like 'regex buddy' that allows you to paste in regexp and figure out what they do should you come across them in code, and use a real parser for parsing. The python <a href="https://docs.python.org/3/howto/regex.html#more-metacharacters">documentation</a> will explain metacharacters like *, ?, + which are repetition operators or ^ $. You can add more examples and run them in this recitation notebook.
</p>
</div>
</div>

<div id="outline-container-org64e484b" class="outline-3">
<h3 id="org64e484b">Finite State Automata</h3>
<div class="outline-text-3" id="text-org64e484b">
<p>
A diversion into theoretical CS so you can understand regular languages and expressions as a finite automaton then all these Kleene star notations and repetition/assertion operators will make sense. You can understand DFAs even if you haven't taken set theory in the math workshop. 
</p>

<ul class="org-ul">
<li><a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=f0c960c5-1c95-4664-b36e-21c8f82ebb45">Finite Automata</a> 15-251 Great Theoretical Ideas in CS
<ul class="org-ul">
<li>In the beginning the slides are slightly out of order, match with <a href="http://www.cs.cmu.edu/~aada/courses/15251s15/www/slides/lec04.pdf">these</a> slides.</li>
</ul></li>
</ul>

<p>
The accepting state in a regular expression is a matching state. The 5 tuple he describes, is similar to the definition of an algorithm in the first chapter of <i>The Art of Computer Programming vol 1</i> by Knuth. Now you know how to do those exercises should you ever read that book. 
</p>

<p>
Around 59:25 we begin regular operations, concatenation (multiplication), union and star.
</p>
<ul class="org-ul">
<li>Example: Concatenation
<ul class="org-ul">
<li>\(L_1\) = {00,10}; \(L_2\) = {0,1} then \(L_1 \cdot L_2\) = {000, 001, 100, 101}</li>
<li>The dot notation is dropped in regex, abc is still multiplication</li>
</ul></li>
<li>Example: Star, the concatenation of i copies of L for i &gt; 0
<ul class="org-ul">
<li>If L = {0,1} then \(L^{2}\) = {00, 01, 10, 11} (L x L concatenated) and \(L^{*}\) = {none, 0, 00, 0000, 01, 111, 01110 etc}</li>
<li>Select any finite number of strings from the language and concat them all together (including possibility of no strings selected, as empty concat empty gives empty)</li>
</ul></li>
</ul>

<p>
Their example regular expression of 'x starts and ends with the same char, in the language L of {a,b} then \(L^{*}\) would be {a, b, aa, bb, aaa, bbb, ababa, etc}
</p>

<p>
a(a|b)*a | b(a|b)*b | a | b which translates to: a concatenated with any amount of a's or b's, and ends with a, OR b concatenated with any amount of a's or b's, ending with b OR a OR b 
</p>

<p>
There is also order precedence: Repetition like ?, star (highest), concat, union (lowest) unless you use parenthesis to denote order. For example ab* is a(b*). 
</p>

<p>
Some regex and their corresponding state diagrams:
</p>

<ul class="org-ul">
<li>The <a href="https://chortle.ccsu.edu/FiniteAutomata/Section07/sect07_15.html">automaton</a> for "a?bc" (matches empty string as well)</li>
<li>Kleene star <a href="https://chortle.ccsu.edu/FiniteAutomata/Section07/sect07_16.html">matching</a> example and it's corresponding <a href="https://chortle.ccsu.edu/FiniteAutomata/Section07/sect07_17.html">automaton</a> for [fr]*og
<ul class="org-ul">
<li>the DFA explains why [fr]*og matches "og" as well as "frog", * will also match empty, so this regex is any combination of f or r (ffffff, or rr), or nothing, concatenated with og</li>
</ul></li>
<li>The regex <a href="https://chortle.ccsu.edu/FiniteAutomata/Section07/sect07_20.html">automaton</a> for "[A-Z]+[aeiou]+[bd]?"
<ul class="org-ul">
<li>Two acceptance states, because [bd]? is none or b or d</li>
</ul></li>
<li>The <a href="https://chortle.ccsu.edu/FiniteAutomata/Section08/sect08_6.html">automaton</a> for "[abc]+[123]*|[def]*[456]+"</li>
<li>The <a href="https://chortle.ccsu.edu/FiniteAutomata/Section08/sect08_9.html">automaton</a> for "([A-C][0-3][D-F])+"</li>
</ul>
</div>


<div id="outline-container-org2e09113" class="outline-4">
<h4 id="org2e09113">Assignment 1</h4>
<div class="outline-text-4" id="text-org2e09113">
<p>
Walking through the first assignment the the rest won't be as verbose. Let's try <a href="https://www.datasciencecourse.org/assignments/homework-1/">homework 1</a>. Untar it and run 'pip install -r requirements.txt'. Get Started notebook, you fill in rotate list and reverse dict, both of which are easy one liners straight from the previous lectures. Rotate list is return list slice + list slice, reverse dict is return swapped keys for a,b in d.items(). The second task is write some tests, notice this is an oracle, it consumes a function and then tests it. You need to add @test decorator and name your test function as specified in the notebook
</p>

<pre class="example">
@test
def successor(n):
    return n + 1

def successor_test(successor):
    test.equal(successor(0), 1)
    test.equal(successor(1), 2)
</pre>

<p>
The next notebook, Scraper, install requirements.txt again with pip. You unfortunately have to create a Yelp account to use the API, and this means relentless spam so use a throwaway email. How I'm doing this assignment is keep open the <a href="https://docs.python.org/3.8/tutorial/">python tutorial</a>, keep open the course notes which have almost all the information you'll need, keep open the library documentation for BeautifulSoup and Requests, and the Yelp API documentation. 
</p>

<p>
<b>Jupyter Notebook/IPython issues</b>
</p>

<ul class="org-ul">
<li>If you get a persistent @test error 'TypeError: 'dict' object is not callable' or something similar, restart the kernel. You can try %history -g dict to see what command may have corrupted your state but I think I spent an hour trying to figure out this cryptic error only to discover it vanishes upon kernel reset.</li>
<li>Annoying indentation <a href="https://www2.cs.arizona.edu/people/mccann/errors-python">errors</a>, don't use tab use spaces</li>
<li>Global variables, a few times I forgot I was actually hacking around with some global reponse variable 'r' I designated to slice apart some nested dictionary/list and test some things, only later to wonder why my tests weren't passing.</li>
<li>Jupyter config can be done in the browser dom or peristent config in a local .json file</li>
<li>Reserved keywords, to see what they are:</li>
</ul>

<details>
<pre class="example">
import keyword
keyword.kwlist

['False',
 'None',
 'True',
 'and',
 'as',
 'assert',
 'async',
 'await',
 'break',
 'class',
 'continue',
 'def',
 'del',
 'elif',
 'else',
 'except',
 'finally',
 'for',
 'from',
 'global',
 'if',
 'import',
 'in',
 'is',
 'lambda',
 'nonlocal',
 'not',
 'or',
 'pass',
 'raise',
 'return',
 'try',
 'while',
 'with',
 'yield']
</pre>
</details>

<p>
<b>Q0: Basic HTTP Requests</b>
</p>

<p>
You may have to change the test to: test.true("This domain is for use in illustrative examples in documents." in text). This is just a requests.get(url), and return the status code, r.text
</p>

<p>
<b>Q1: Authenticated HTTP Request with the Yelp API</b>
</p>

<p>
We'll need the Yelp API <a href="https://www.yelp.com/developers/documentation/v3/business_search">documentation</a>. A warning about the API, it may block your key for 24 hours if you do too many requests too quickly trying to figure out the assignment, I highly recommend retrieving once and then storing that in some global variable so you can hack around with the response unpacking the content instead of repeated calls. I used .content here instead of text to play around with the binary response in other cells, you would probably want .text
</p>

<details>
<pre class="example">
def yelp_search_test(yelp_search):
    total, business = yelp_search(read_api_key(), "Pittsburgh")
    test.true(abs(total - 2600) &lt; 60)
    expected_keys = ['id', 'name', 'phone', 'review_count']
    if len(business):
        test.true(all(k in set(business[0].keys()) for k in expected_keys))

@test
def yelp_search(api_key, query):
    """
    Make an authenticated request to the Yelp API.

    Args:
        query (string): Search term

    Returns:
        total (integer): total number of businesses on Yelp corresponding to the query
        businesses (list): list of dicts representing each business
    """
    api = 'https://api.yelp.com/v3/businesses/search'
    headers = {'Authorization': 'Bearer ' + api_key}
    params = {'location': query}
    r = requests.get(api, params=params, headers=headers).content
    s = json.loads(r)
    return s['total'], s['businesses']
</pre>
</details>

<p>
<b>Q2: Aquire all of the restaurants in Pittsburgh (on Yelp)</b>
</p>

<p>
I cut + paste the yelp search function but added an extra parameter 'offset' and returned only r['businesses']. I also experimented here seeing how many python builtins I could chain together (again using binary r.content, you probably want r.text). This violates DRY principal obviously, if this wasn't an assignment you'd generalize yelp search to take a parameter of how many businesses you want from the API.
</p>

<details>
<pre class="example">
def all_restaurants(api_key, query, offset):
    """
    Retrieve ALL the restaurants on Yelp for a given query.

    Args:
        query (string): Search term

    Returns:
        results (list): list of dicts representing each business
    """
    api = 'https://api.yelp.com/v3/businesses/search'
    headers = {'Authorization': 'Bearer ' + api_key}
    params = {'location': query, 'limit': '50', 'offset': offset}
    r = json.loads(
        requests.get(api, params=params, headers=headers)
        .content)   
    return r["businesses"]
</pre>
</details>

<p>
You could have this inside the all restaurants function or in a seperate cell and keep all restaurants generalized to call for any offset. There's probably a <i>pythonic</i> <a href="https://www.python.org/dev/peps/pep-0008/">recommended</a> way to do this, I'm just haphazardly scripting away on cruise control. You can check your code with pycodestyle &#x2013;show-source file.py (pip install pycodestyle) or use a linter for this in PyCharm and other IDEs. 
</p>

<details>
<pre class="example">
# Yelp API docs: up to 1k results, max 50 returned at once
# Use offset parameter to get next 50, and so on
# Use time library so you don't get blocked

# Can also append to a dict w/content[i] for i in range()
content = []
for y in range(0, 1000, 50):
    content += list(all_restaurants(read_api_key(), 'Polish, Hill, Pittsburgh', y))
    time.sleep(.3)

print(len(content))
print([x['name'] for x in content])
</pre>
</details>

<p>
<b>Q2.5 Parse the API Responses and Extract the URLs</b>
</p>

<p>
Jam the string into a json dict and use another list comprehension
</p>

<details>
<pre class="example">
def parse_api_response_test(parse_api_response):
    test.equal(parse_api_response(json_src), ['https://www.yelp.com/biz/four-barrel-coffee-san-francisco'])

@test
def parse_api_response(data):
    """
    Parse Yelp API results to extract restaurant URLs.
    
    Args:
        data (string): String of properly formatted JSON.

    Returns:
        (list): list of URLs as strings from the input JSON.
    """
    dict_json = json.loads(data)
    return [x['url'] for x in dict_json['businesses']]
</pre>
</details>

<p>
<b>Q3: Parse a Yelp restaurant Page</b>
</p>

<p>
Yelp has changed their page since this assignment was written, all the information is in a script tag now. There's some assignment tests to return 'page count' (20 per page) not the total count, which is integer division, and you have to cast the ratings to floats. What I did here was first dump the page into beautifulsoup and noticed what I wanted was all in the &lt;script&gt; tags, specifically the third element with that tag. Then I dumped the text into json.loads() and printed the keys to see which one's I could iterate on, and used a list comprehension to return the dict keys and page total as a tuple. 
</p>


<details>
<pre class="example">
def parse_page(html):
 """
   Parse the reviews on a single page of a restaurant.
    Args:
       html (string): String of HTML corresponding to a Yelp restaurant
    Returns:
       Tuple[List[Dict], int]: a tuple of two elements
           first element: list of dictionaries corresponding to the extracted review information
           second element: number of pages total.
   """
    soup = BeautifulSoup(html, 'html5lib')
    json_extract = soup.select("[type='application/ld+json']")[3]
    json_dict = json.loads(json_extract.text)
    return [{'author': x['author'],
            'rating': float(x['reviewRating']['ratingValue']),
            'date': x['datePublished'],
            'description': x['description']} 
           for x in json_dict['review']], json_dict['aggregateRating']['reviewCount']//20
</pre>
</details>

<p>
<b>Q3.5: Extract all the Yelp reviews for a Single Restaurant</b>
</p>

<p>
This assignment the yelp url goes up by 20 each time, so after page one you add ?start=20, ?start=40, to offset the reviews. I actually did this assignment incorrectly and instead used the API to get all the reviews, then when rereading figured out I was supposed to crawl each page. Essentially this is the same as other assignments you can either grab the itemprop tags or you can grab the type=application/json in the &lt;script&gt; again, except you will have to use regex to clean up the beginning and end capturing everything after &lt;!&#x2013; and everything before &#x2013;&gt; which is grouping that we did in the lecture. I selected soup.select("[type='application/json']")[2] for every page after the first page, cleaned it w/regex, returned group(1) and loaded this in a json dict which then was trivial to use a comprehension to return all the desired nested values. The first page you extract the page count and then this is your range to loop over. 
</p>

<p>
Now you can scrape any page you want, and are familiar with APIs.  
</p>
</div>
</div>


<div id="outline-container-orgc54d175" class="outline-4">
<h4 id="orgc54d175">Assignment 1 15-688 (Optional)</h4>
<div class="outline-text-4" id="text-orgc54d175">
<p>
The graduate version of this course has it's own <a href="http://www.datasciencecourse.org/assignments/homework-1/">homework</a>, and expects you already have an undergrad where you programmed in some OOP language for a year or so, so is up to you if you want to try the homework. For hw1_xml_parser.ipynb remember the automatons from the DFA lecture, keep one in your head and process the characters sending them to a non accepting loop or to a matching state, being aware of greedy matching vs lazy matching. 
</p>

<p>
<b>Q1: Regular expression for identifying tags</b>
</p>

<p>
Answers go in the second code box, above test_snippet="bunch of xml":
</p>

<pre class="example">
... other regexs
comment = re.compile(r'&lt;!--(.[^-]*)')
xml_prolog = re.compile(r'(xml version.+")')
html_declaration = re.compile(r'DOCTYPE \w*')
</pre>

<p>
For my comment regex, I got [^-] from <a href="https://developers.google.com/edu/python/regular-expressions#greedy-vs.-non-greedy-optional">here</a> "all of these chars except stopping at X" so stop on the - in &#x2013;&gt;. There's probably a hundred different ways to match these strings.
</p>

<p>
There is some weird spacing with their tests:
</p>
<pre class="example">
Mine   [('note', 'date="8/31/12"'), ('to', ''), ('from', ''), ('heading', 'type="Reminder"/'), ('body', ''), ('h1', ''), ('p', '')]
Theirs [('note', ' date="8/31/12"'), ('to', ''), ('from', ''), ('heading', ' type="Reminder"/'), ('body', ''), ('h1', ''), ('p', '')])

date and type='Reminder' have a space for some reason,  only test I failed
</pre>

<p>
<b>Q2: XML Parser</b>
</p>

<p>
There is actually a paper floating around of somebody who parsed XML with a <a href="https://www2.cs.sfu.ca/~cameron/REX.html">single</a> regex but since XML is not a regular language you would never want to do this and instead use/make a real parser. For this assignment try the following then you'll get what you have to do, you already made tag_open, tag_close, comment etc., in the last assignment. 
</p>

<ul class="org-ul">
<li>matchopen = tag_open.search(test_snippet, 117)  #search(text-to-search, position)
<ul class="org-ul">
<li>&lt;re.Match object; span=(138, 142), match='&lt;to&gt;'&gt;</li>
</ul></li>
<li>matchclosed = tag_close.search(test_snippet, 117)
<ul class="org-ul">
<li>&lt;re.Match object; span=(146, 151), match='&lt;/to&gt;'&gt;</li>
</ul></li>
</ul>

<p>
So you follow the algorithm they've described, testing with if-statements for a match, and moving around the matches using the .position methods like match.end() or span. 
</p>

<p>
<b>Q3: Searching for tags</b>
</p>

<p>
I actually didn't try this one, since I spent longer than I wanted on the XML parser, and we can only do so many assignments on regex parsing hacks. It consumes an XMLNode and then searches for tags so isn't a lot of code to write. I put this in a todo notebook, anytime I run out of time for an assignment the unfinished ones go in there and later I go back and see if I can redo them, or if it's worth the time to redo them.    
</p>
</div>
</div>
</div>


<div id="outline-container-orgcc1561d" class="outline-3">
<h3 id="orgcc1561d">Lecture 4 Relational Data</h3>
<div class="outline-text-3" id="text-orgcc1561d">
<p>
Standard dbms crash course, more <a href="https://functionalcs.github.io/web/#org268f85c">here</a> if you're interested in learning some advanced sql like CTEs (common table expressions) where you just declare everything up front 'here's what I want' in a single statement and the dbms optimizes the query for you. Reminder you can load the notes for this lecture in jupyter notebook and test out all the Pandas functions as he introduces them. 
</p>
</div>
</div>


<div id="outline-container-org847d894" class="outline-3">
<h3 id="org847d894">Lecture 5 Visualizations</h3>
<div class="outline-text-3" id="text-org847d894">
<p>
This lecture is about making your own visualizations for data exploration much like how we wrote examples in CS019 in the software workshop to better understand the full domain of the problem. Some good advice in here about how not to visualize, like never using a pie chart. There's no code in this lecture.
</p>
</div>
</div>

<div id="outline-container-orgca620c2" class="outline-3">
<h3 id="orgca620c2">Lecture 6 Linear Algebra</h3>
<div class="outline-text-3" id="text-orgca620c2">
<p>
None of this will make sense unless you've done a bit of linear algebra already. 
</p>
</div>

<div id="outline-container-org692e721" class="outline-4">
<h4 id="org692e721">Vector Boot Camp</h4>
<div class="outline-text-4" id="text-org692e721">
<p>
This <a href="http://www.math.brown.edu/~dkatz/vectorbootcamp/">crash course</a> from Brown University, 3 tutorials on vectors, scalars, dot/cross product and a worksheet of <a href="http://www.math.brown.edu/~dkatz/vectorbootcamp/vector-boot-camp-problems.pdf">exercises</a> with <a href="http://www.math.brown.edu/~dkatz/vectorbootcamp/vector-boot-camp-solutions.pdf">solutions</a> to practice. todo
</p>
</div>
</div>

<div id="outline-container-org7970826" class="outline-4">
<h4 id="org7970826">Linear Algebra Review</h4>
<div class="outline-text-4" id="text-org7970826">
<p>
The same prof has a linear algebra <a href="https://www.youtube.com/playlist?list=PLC7GP7QTnIJ8w2qcrHK1nIy7mWQnYSOmr">crash course</a> where this material is better explained, with <a href="https://www.cs.cmu.edu/~zkolter/course/15-884/linalg-review.pdf">notes</a>. Technically this is all you need for this data science course. 
</p>
</div>
</div>

<div id="outline-container-org8622db2" class="outline-4">
<h4 id="org8622db2">Future Linear Algebra</h4>
<div class="outline-text-4" id="text-org8622db2">
<p>
Because linear algebra plays such an essential role we'll end up doing 3 courses on it, one geometric focused course in the math workshop that can be done leisurely and covers some more advanced topics, Brown's <a href="http://cs.brown.edu/courses/cs053/current/lectures.htm">CS053</a> <i>Coding the Matrix</i> which is complex field Linear Algebra entirely done in Python, and Gilbert Strang's <a href="https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/video-lectures/">18.065</a> <i>Linear Algebra with Deep Learning</i> a second more advanced course in function optimization, stats and neural nets. 
</p>
</div>
</div>


<div id="outline-container-org1ee8c79" class="outline-4">
<h4 id="org1ee8c79">Assignment 2</h4>
<div class="outline-text-4" id="text-org1ee8c79">
<p>
<a href="http://www.datasciencecourse.org/assignments/homework-2/">todo</a>
</p>
</div>
</div>
</div>
</div>
</div>
</body>
</html>
